# -*- coding: utf-8 -*-
"""Copy of TF_IDF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O1kE3Z0b100iPvSt6pjFtPKZ3LN81cI_
"""

from google.colab import files

uploaded = files.upload()

"""**TEST-TRAIN SPLITTING VALIDATION**"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

# Load the dataset
df = pd.read_excel('dataset.xlsx')

# Split the dataset into training and testing sets
train_data, test_data, train_labels, test_labels = train_test_split(df['text'], df['category'], test_size=0.2, random_state=42)

# Create a TfidfVectorizer object to transform the text data into numerical features
vectorizer = TfidfVectorizer()

# Transform the training and testing data
train_features = vectorizer.fit_transform(train_data)
test_features = vectorizer.transform(test_data)

# Train the model for 5 epochs
for epoch in range(5):
    # Create a Multinomial Naive Bayes classifier
    classifier = MultinomialNB()

    # Fit the classifier to the training data
    classifier.fit(train_features, train_labels)

    # Predict the labels for the testing data
    test_pred = classifier.predict(test_features)

    # Calculate the accuracy of the classifier on the testing data
    accuracy = accuracy_score(test_labels, test_pred)
    print(f'Epoch {epoch+1} - Accuracy: {accuracy:.4f}')

"""**Confusion Matrix**"""

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
loss_score = classifier.score(test_features, test_labels)
Accuracy_score = accuracy_score(test_labels, test_pred)
precision_score = precision_score(test_labels, test_pred, average='weighted')
recall_score = recall_score(test_labels, test_pred, average='weighted')
f_score = f1_score(test_labels, test_pred, average='weighted')
confusion_matrix = confusion_matrix(test_labels, test_pred)
print("Loss score:", loss_score)
print("Accuracy score:", Accuracy_score)
print("Precision score:", precision_score)
print("Recall score:", recall_score)
print("F-score:", f_score)
print("Confusion matrix:\n", confusion_matrix)

"""**Classification Of input questions**"""

from collections import Counter
tm=int(input("Enter total marks:"))
tt=int(input("Enter total time for attempting the question paper in minutes:"))
rem_marks=tm
rem_time=tt
marks=0
difficulty=[]
level=[]
while rem_marks>0:
    ques=input("Enter your question:")
    new_question_features = vectorizer.transform([ques])
    new_question_pred = classifier.predict(new_question_features)[0]
    time=int(input("Enter estimated time to attempt this question:"))
    if(time>rem_time):
      print("Time exceeded!! Remaining time limit: ",rem_time)
      continue
    else:
      marks=int(input("Enter marks of question:"))
      if(marks>rem_marks):
        print("Marks exceeded!! Remaining marks limit: ",rem_marks)
        continue
      else:
        rem_time-=time
        diff=input("Enter difficulty level:")
        difficulty.append(diff)
        level.append(new_question_pred)
        rem_marks-=marks
        print(f"The level of the question is: {new_question_pred}")

c1=Counter(difficulty)
c2=Counter(level)

import matplotlib.pyplot as plt
print("                                                             QUESTION PAPER ANALYSIS REPORT                                     ")
print("----------------------------------------------------------------------------------------------------------------------------------------------------------------------*----------------------------")
length=len(c2)
length1=len(c1)
print("Extra Time remaining in minutes:",rem_time)
print("------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------")
colors=['purple', 'pink', 'cyan','red','blue','brown']
ques_values =list(c2.values() ) 
ques_levels=list(c2.keys())
plt.pie(ques_values,labels=ques_levels,colors=colors, startangle=90, shadow=True,explode=(0.1,)*length, autopct='%1.2f%%')
print("Level wise analysis of Question Paper")
plt.show()
print("------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------")
diff_values =list(c1.values() ) 
difficulty_levels=list(c1.keys())
plt.pie(diff_values,labels=difficulty_levels,shadow=True,explode=(0.1,)*length1, autopct='%1.2f%%')
print("Difficulty wise analysis of Question Paper")
plt.show()



"""**K FOLD CROSS VALIDATION**"""

df = pd.read_excel('dataset.xlsx')

# separate the texts and labels
texts = df['text']
labels = df['category']

# initialize TF-IDF vectorizer
vectorizer = TfidfVectorizer()

# vectorize the texts
X = vectorizer.fit_transform(texts)

# initialize Naive Bayes classifier
clf = MultinomialNB()

# define the number of folds for cross-validation
n_folds = 5

# initialize k-fold cross-validation
kf = KFold(n_splits=n_folds, shuffle=True)

# initialize list to store accuracies for each fold
accs = []

# iterate over the folds
for train_index, test_index in kf.split(X):
    # split the data into training and testing sets for this fold
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = labels[train_index], labels[test_index]

    # fit the classifier on the training set
    clf.fit(X_train, y_train)

    # predict on the testing set
    y_pred = clf.predict(X_test)
    i=1

    # calculate accuracy and store it in the list
    Acc = accuracy_score(y_test,y_pred)
    accs.append(Acc)
    print('For FOLD',i,Acc)
    i+=1
    

# calculate and print the mean accuracy over all folds
print('Mean accuracy:', sum(accs)/n_folds)

