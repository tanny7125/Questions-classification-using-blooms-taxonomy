# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16z2LoXXSLzqN81T_N9KUxpOYZi-gTOFr
"""

from google.colab import files
upload=files.upload()

pip install transformers

import pandas as pd
import numpy as np
import torch
from tqdm.auto import tqdm
import tensorflow as tf
import torch.utils.data
from torch.utils.data import TensorDataset
from transformers import TFBertModel, BertTokenizer
import joblib
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support

df= pd.read_excel("dataset.xlsx")
category_map={
    "Knowledge": 0,
    "Comprehension": 1,
    "Application": 2,
    "Analysis": 3,
    "Synthesis": 4,
    "Evaluation": 5
}
df["category"]=df["category"].map(category_map)
df.to_excel("dataset.xlsx",index=False)

df.head()

df['category'].value_counts()

tokenizer= BertTokenizer.from_pretrained('bert-base-cased')

token = tokenizer.encode_plus(
    df['text'].iloc[0], 
    max_length=256, 
    truncation=True, 
    padding='max_length', 
    add_special_tokens=True,
    return_tensors='tf'
)

X_input_ids = np.zeros((len(df), 256))
X_attn_masks = np.zeros((len(df), 256))

def generate_training_data(df, ids, masks, tokenizer):
    for i, text in tqdm(enumerate(df['text'])):
        tokenized_text = tokenizer.encode_plus(
            text,
            max_length=256, 
            truncation=True, 
            padding='max_length', 
            add_special_tokens=True,
            return_tensors='tf'
        )
        ids[i, :] = tokenized_text.input_ids
        masks[i, :] = tokenized_text.attention_mask
    return ids, masks

X_input_ids, X_attn_masks = generate_training_data(df, X_input_ids, X_attn_masks, tokenizer)

labels = np.zeros((len(df), 6))
labels.shape

labels[np.arange(len(df)), df['category'].values] = 1

labels

dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))

def BloomsDatasetMapFunction(input_ids, attn_masks, labels):
    return {
        'input_ids': input_ids,
        'attention_mask': attn_masks
    }, labels

dataset = dataset.map(BloomsDatasetMapFunction)

dataset = dataset.shuffle(10000).batch(16, drop_remainder=True)

dataset.take(1)

percentage=0.8
train_size=int((len(df)//16)*percentage)

train_dataset = dataset.take(train_size)
val_dataset = dataset.skip(train_size)
len(train_dataset),len(val_dataset

model = TFBertModel.from_pretrained('bert-base-cased')

input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')
attn_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')

bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1] 
intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)
output_layer = tf.keras.layers.Dense(6, activation='softmax', name='output_layer')(intermediate_layer)

Blooms_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)
Blooms_model.summary()

optim = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5, decay=1e-6)
loss_func = tf.keras.losses.CategoricalCrossentropy()
acc = tf.keras.metrics.CategoricalAccuracy('accuracy')

Blooms_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])

from sklearn.metrics import confusion_matrix, precision_recall_fscore_support

for epoch in range(5):
    # Train the model for one epoch
    hist = Blooms_model.fit(
        train_dataset,
        validation_data=val_dataset
    )
    
    # Evaluate the model on the validation set
    val_loss, val_acc = Blooms_model.evaluate(val_dataset, verbose=0)
    print(f"Epoch {epoch + 1}: Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.3f}")

y_true, y_pred = [], []
    for x, y in val_dataset:
        y_true.extend(tf.argmax(y, axis=1).numpy())
        y_pred.extend(tf.argmax(Blooms_model.predict(x), axis=1).numpy())
    
    # Calculate confusion matrix and classification report
    cm = confusion_matrix(y_true, y_pred)
    print("Confusion Matrix:")
    print(cm)
    print("Classification Report:")
    print(precision_recall_fscore_support(y_true, y_pred, average='weighted'))

joblib.dump(tokenizer,'Finalbert_tokenizer.joblib')
Blooms_model.save('Finalbert_model.h5')

from google.colab import drive
drive.mount('/content/drive')

tokenizer = joblib.load('/content/drive/My Drive/Finalbert_tokenizer.joblib')
model = tf.keras.models.load_model('/content/drive/My Drive/Finalbert_model.h5', custom_objects={'TFBertModel': TFBertModel})

def classify_question(question):
    
    encoded_question = tokenizer.encode_plus(
        question,
        max_length=256,
        truncation=True,
        padding='max_length',
        return_attention_mask=True,
        return_token_type_ids=False,
        return_tensors='tf'
    )
    input_ids = encoded_question['input_ids']
    attn_mask = encoded_question['attention_mask']
    
    # Make predictions and return the predicted class name
    prediction = model.predict([input_ids, attn_mask])#testcase: model used
    predicted_class_num = tf.argmax(prediction, axis=1).numpy()[0]
    
    # Map the class number to the class name
    
    class_names = ["Knowledge", "Comprehension", "Application", "Analysis", "Synthesis", "Evaluation"]
    predicted_class_name = class_names[predicted_class_num]
    
    if question=="" or question.isspace():
      return("Please enter a valid question!!")

    else:
      return(predicted_class_name)

from collections import Counter
tm=int(input("Enter total marks:"))
tt=int(input("Enter total time for attempting the question paper in minutes:"))
rem_marks=tm
rem_time=tt
marks=0
difficulty=[]
level=[]
while rem_marks>0:
    ques=input("Enter your question:")
    level_name = classify_question(ques)
    time=int(input("Enter estimated time to attempt this question:"))
    if(time>rem_time):
      print("Time exceeded!! Remaining time limit: ",rem_time)
      continue
    else:
      marks=int(input("Enter marks of question:"))
      if(marks>rem_marks):
        print("Marks exceeded!! Remaining marks limit: ",rem_marks)
        continue
      else:
        rem_time-=time
        diff=input("Enter difficulty level:")
        difficulty.append(diff)
        level.append(level_name)
        rem_marks-=marks
        print(f"The level of the question is: {level_name}")

c1=Counter(difficulty)
c2=Counter(level)

import matplotlib.pyplot as plt
print("                                                             QUESTION PAPER ANALYSIS REPORT                                     ")
print("----------------------------------------------------------------------------------------------------------------------------------------------------------------------*----------------------------")
length=len(c2)
length1=len(c1)
print("Extra Time remaining in minutes:",rem_time)
print("------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------")
colors=['purple', 'pink', 'cyan','red','blue','brown']
ques_values =list(c2.values() ) 
ques_levels=list(c2.keys())
plt.pie(ques_values,labels=ques_levels,colors=colors, startangle=90, shadow=True,explode=(0.1,)*length, autopct='%1.2f%%')
print("Level wise analysis of Question Paper")
plt.show()
print("------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------")
diff_values =list(c1.values() ) 
difficulty_levels=list(c1.keys())
plt.pie(diff_values,labels=difficulty_levels,shadow=True,explode=(0.1,)*length1, autopct='%1.2f%%')
print("Difficulty wise analysis of Question Paper")
plt.show()